{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\AJAY\n",
      "[nltk_data]     BISWAS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import fasttext\n",
    "import pandas as pd\n",
    "import random\n",
    "from resources.tokTT import CommentTokenizer as CT\n",
    "from resources.basicIO import InputOutput as IO\n",
    "from resources.basicIO import InputOutput as IO\n",
    "from resources.filterLang import FilterLanguage as FL\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import fasttext\n",
    "import pandas as pd\n",
    "from scipy import spatial\n",
    "from scipy.spatial import distance\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "#from sklearn.linear_model import LassoLars\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import copy\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Corpus and Random Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_corpus = IO.load_text('datasets/corpus.txt')\n",
    "tokenized_corpus = CT.cleaned('datasets/corpus.txt')\n",
    "IO.save_text('datasets/tokenized_corpus.txt',tokenized_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Fasttext Unsupervised Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = fasttext.train_unsupervised(input=\"datasets/tokenized_corpus.txt\", lr=0.01, epoch=30, wordNgrams=2, dim=300)\n",
    "model_2.save_model(\"models/ft_unsupervised_N_2.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus\n",
    "df_dict = {'raw_comment': raw_corpus, 'tokenized_comment': tokenized_corpus}\n",
    "df_corpus = pd.DataFrame(df_dict)\n",
    "df_corpus.to_csv('datasets/corpus_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random sample\n",
    "text = IO.load_csv_col('datasets/random_sample.csv', 'comment')\n",
    "text_labels = IO.load_csv_col('datasets/random_sample.csv', 'label')\n",
    "text_labels = list(map(str, map(int, text_labels)))\n",
    "text_TK = [CT.tokenize(x) for x in text]\n",
    "\n",
    "df_dict = {'raw_comment': text, 'tokenized_comment': text_TK, 'label': text_labels}\n",
    "df_sample = pd.DataFrame(df_dict)\n",
    "df_sample.to_csv('datasets/random_sample_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unnecessary comments\n",
    "df_sample = df_sample.drop([x for x in range(len(df_sample)) if int(\n",
    "    df_sample['label'][x]) != 0 and int(df_sample['label'][x]) != 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_comment</th>\n",
       "      <th>tokenized_comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3358</th>\n",
       "      <td>Farmers are rights</td>\n",
       "      <td>farmer be right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3360</th>\n",
       "      <td>Spineless modi  now this will boost confidence...</td>\n",
       "      <td>spineless modi now this will boost confidence ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3362</th>\n",
       "      <td>These three laws are very beneficial to farmer...</td>\n",
       "      <td>these three law be very beneficial to farmer o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3363</th>\n",
       "      <td>Farmers are not terrorist</td>\n",
       "      <td>farmer be not terrorist</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3419</th>\n",
       "      <td>We stand with Indian farmers,  down with all o...</td>\n",
       "      <td>we stand with indian farmer down with all oppr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            raw_comment  \\\n",
       "3358                                 Farmers are rights   \n",
       "3360  Spineless modi  now this will boost confidence...   \n",
       "3362  These three laws are very beneficial to farmer...   \n",
       "3363                         Farmers are not terrorist    \n",
       "3419  We stand with Indian farmers,  down with all o...   \n",
       "\n",
       "                                      tokenized_comment label  \n",
       "3358                                    farmer be right     0  \n",
       "3360  spineless modi now this will boost confidence ...     0  \n",
       "3362  these three law be very beneficial to farmer o...     1  \n",
       "3363                            farmer be not terrorist     0  \n",
       "3419  we stand with indian farmer down with all oppr...     0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1378\n",
       "1    1040\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_sample['tokenized_comment'], \n",
    "                                                    df_sample['label'], test_size=0.2, \n",
    "                                                    random_state=42,\n",
    "                                                    stratify=df_sample['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  1934\n",
      "X_test:  484\n"
     ]
    }
   ],
   "source": [
    "print('X_train: ' ,len(X_train))\n",
    "print('X_test: ' ,len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FastTextTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\" Convert texts into their mean fastText vectors \"\"\"\n",
    "\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.stack([np.mean([self.model[w] for w in text.split()], 0) for text in X])\n",
    "\n",
    "\n",
    "def classify(small_model, predictor, lines, Y):\n",
    "    classifier = make_pipeline(\n",
    "        FastTextTransformer(model=small_model),\n",
    "        predictor\n",
    "    ).fit(\n",
    "        lines,\n",
    "        Y\n",
    "    )\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "LR_Normal = classify(model_2, LogisticRegression(random_state=1), X_train, y_train)\n",
    "# SVM\n",
    "SVM_Normal = classify(model_2, svm.SVC(), X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(('LR Normal N=2', LR_Normal))\n",
    "models.append(('SVM Normal N=2', SVM_Normal))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Normal N=2\n",
      "0.731404958677686\n",
      "SVM Normal N=2\n",
      "0.731404958677686\n"
     ]
    }
   ],
   "source": [
    "file = open('results/output_better.txt', 'w+')\n",
    "file.close()\n",
    "\n",
    "outfile = open(\"results/output_better.txt\", \"a\")\n",
    "for i, v in models:\n",
    "    print(i)\n",
    "    accuracy = metrics.accuracy_score(y_test, v.predict(X_test))\n",
    "    confusion_matrix = metrics.confusion_matrix(y_test, v.predict(X_test))\n",
    "    print('========= {} Model Test Results ==========='.format(i), file=outfile)\n",
    "    print(' ', file=outfile)\n",
    "    print(\"Model Accuracy:\" \"\\n\", accuracy, file=outfile)\n",
    "    print(accuracy)\n",
    "    print(' ', file=outfile)\n",
    "    print(\"Confusion matrix:\" \"\\n\", confusion_matrix, file=outfile)\n",
    "    print(' ', file=outfile)\n",
    "outfile.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('clf', LogisticRegression(random_state=1)),\n",
    "                    ])\n",
    "text_clf = text_clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.731404958677686"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = text_clf.predict(X_test)\n",
    "np.mean(predicted == y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.74 (+/- 0.05)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(text_clf, df_sample.tokenized_comment, df_sample.label, cv=10)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seed Set + AVG + Batch + Random Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_seed, X_expand, y_seed, y_expand = train_test_split(X_train,\n",
    "                                                    y_train, test_size=0.99,\n",
    "                                                    random_state=41,\n",
    "                                                    stratify=y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_seed:  19\n",
      "X_expand:  1915\n"
     ]
    }
   ],
   "source": [
    "print('X_seed: ',len(X_seed))\n",
    "print('X_expand: ',len(X_expand))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    11\n",
       "1     8\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_seed.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity and Nearest Neighbor Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(model, line, k):\n",
    "    # words contains all the words in the corpus\n",
    "    lst1 = model.get_nearest_neighbors(line, k)\n",
    "    v1 = []\n",
    "    l1 = [x[1] for x in lst1]\n",
    "    l10 = [x[0] for x in lst1]\n",
    "    for i in range(len(model.words)):\n",
    "        try:\n",
    "            v1.append(l10[l1.index(model.words[i])])\n",
    "        except:\n",
    "            v1.append(0)\n",
    "    return v1\n",
    "\n",
    "def NN(model, line, K):\n",
    "        return model.get_nearest_neighbors(line, k=K)\n",
    "\n",
    "def get_NN(model, lines_TK, k):\n",
    "    scores = []\n",
    "    for line in lines_TK:\n",
    "        scores.append(score(model, line, k))\n",
    "    return scores\n",
    "\n",
    "def cos_sim(a, b):\n",
    "    dot_product = np.dot(a, b)\n",
    "    norm_a = np.linalg.norm(a)\n",
    "    norm_b = np.linalg.norm(b)\n",
    "    if(norm_a * norm_b == 0.0):\n",
    "        return dot_product / (norm_a * norm_b + 0.001)\n",
    "    return dot_product / (norm_a * norm_b)\n",
    "\n",
    "def sim(x, y, sim_type):\n",
    "    if(sim_type == 'cosine_sim'):\n",
    "        return cos_sim(x, y)\n",
    "\n",
    "# find similarity score matrix between A and B\n",
    "# pass transpose of B\n",
    "def sim_matrix(A, B, sim_type):\n",
    "    m, p = A.shape\n",
    "    p, n = B.shape\n",
    "    C = np.zeros((m, n))\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            C[i][j] = sim(A[i, :], B[:, j], sim_type)\n",
    "    return C\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expansion Code (Random Sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Expand_R(model, seed_set_TK, seed_set_label, expansion_TK, expansion_text_labels, batch_size, count, k, random_rate):\n",
    "    seed_TK = copy.deepcopy(seed_set_TK)\n",
    "    seed_labels = copy.deepcopy(seed_set_label)\n",
    "    M = np.arange(0, count, batch_size)\n",
    "    cnt = int(random_rate * batch_size)\n",
    "    count2 = [0]\n",
    "\n",
    "    for i in range(1, len(M)):\n",
    "\n",
    "        print(M[i], end=' ')\n",
    "\n",
    "        exp_TK = expansion_TK[M[i-1]:M[i]]\n",
    "        exp_labels = expansion_text_labels[M[i-1]:M[i]]\n",
    "\n",
    "        seed_NN = get_NN(model, seed_TK, k)\n",
    "        exp_NN = get_NN(model, exp_TK, k)\n",
    "\n",
    "        A = np.array(seed_NN)\n",
    "        B = np.array(exp_NN).T\n",
    "        C = sim_matrix(A, B, \"cosine_sim\")\n",
    "\n",
    "        Y_ind = np.argmax(C, axis=0)\n",
    "        Y = [seed_labels[x] for x in Y_ind]\n",
    "\n",
    "        if(random_rate == 0.0):\n",
    "            # no random sampling\n",
    "            pass\n",
    "        else:\n",
    "            # random sampling\n",
    "            Y_r = random.sample(range(0,len(Y)), cnt)\n",
    "            for j in Y_r:\n",
    "                if(Y[j] == exp_labels[j]):\n",
    "                    count2[0] += 1\n",
    "                Y[j] = exp_labels[j]\n",
    "\n",
    "        seed_labels.extend(Y)\n",
    "        seed_TK.extend(exp_TK)\n",
    "\n",
    "    return seed_TK, seed_labels, count2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 40 60 80 100 120 140 160 180 200 220 240 260 280 300 320 340 360 380 400 420 440 460 480 500 520 540 560 580 600 620 640 660 680 700 720 740 760 780 800 820 840 860 880 900 920 940 960 980 1000 1020 1040 1060 1080 1100 1120 1140 1160 1180 1200 1220 1240 1260 1280 1300 1320 1340 1360 1380 1400 1420 1440 1460 1480 1500 1520 1540 1560 1580 1600 1620 1640 1660 1680 1700 1720 1740 1760 1780 1800 1820 1840 1860 1880 1900 "
     ]
    }
   ],
   "source": [
    "X_train_exp, y_train_exp, count2 = Expand_R(model_2, \n",
    "                                  X_seed.to_list(), \n",
    "                                  y_seed.to_list(), \n",
    "                                  X_expand.to_list(), \n",
    "                                  y_expand.to_list(),\n",
    "                                  20,\n",
    "                                  len(y_expand),\n",
    "                                  20,\n",
    "                                  0.2\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n"
     ]
    }
   ],
   "source": [
    "print(count2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "LR_Normal_e = classify(model_2, LogisticRegression(\n",
    "    random_state=1), X_train_exp, y_train_exp)\n",
    "# SVM\n",
    "SVM_Normal_e = classify(model_2, svm.SVC(), X_train_exp, y_train_exp)\n",
    "\n",
    "\n",
    "models_e = []\n",
    "models_e.append(('LR Normal N=2', LR_Normal_e))\n",
    "models_e.append(('SVM Normal N=2', SVM_Normal_e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Normal N=2\n",
      "0.6756198347107438\n",
      "SVM Normal N=2\n",
      "0.6363636363636364\n"
     ]
    }
   ],
   "source": [
    "file = open('results/output_better_exp.txt', 'w+')\n",
    "file.close()\n",
    "\n",
    "outfile = open(\"results/output_better_exp.txt\", \"a\")\n",
    "for i, v in models_e:\n",
    "    print(i)\n",
    "    accuracy = metrics.accuracy_score(y_test, v.predict(X_test))\n",
    "    confusion_matrix = metrics.confusion_matrix(y_test, v.predict(X_test))\n",
    "    print('========= {} Model Test Results ==========='.format(i), file=outfile)\n",
    "    print(' ', file=outfile)\n",
    "    print(\"Model Accuracy:\" \"\\n\", accuracy, file=outfile)\n",
    "    print(accuracy)\n",
    "    print(' ', file=outfile)\n",
    "    print(\"Confusion matrix:\" \"\\n\", confusion_matrix, file=outfile)\n",
    "    print(' ', file=outfile)\n",
    "outfile.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expansion Code (Active Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Expand_A(model, seed_set_TK, seed_set_label, expansion_TK, \n",
    "             expansion_text_labels, batch_size, count, k, sim_threshold):\n",
    "    \n",
    "    seed_TK = copy.deepcopy(seed_set_TK)\n",
    "    seed_labels = copy.deepcopy(seed_set_label)\n",
    "    M = np.arange(0, count, batch_size)\n",
    "\n",
    "    count2 = [0]\n",
    "\n",
    "    for i in range(1, len(M)):\n",
    "\n",
    "        print(M[i], end=' ')\n",
    "\n",
    "        exp_TK = expansion_TK[M[i-1]:M[i]]\n",
    "        exp_labels = expansion_text_labels[M[i-1]:M[i]]\n",
    "\n",
    "        seed_NN = get_NN(model, seed_TK, k)\n",
    "        exp_NN = get_NN(model, exp_TK, k)\n",
    "\n",
    "        A = np.array(seed_NN)\n",
    "        B = np.array(exp_NN).T\n",
    "        C = sim_matrix(A, B, \"cosine_sim\")\n",
    "\n",
    "        Y_ind = np.argmax(C, axis=0)\n",
    "        Y_val = np.amax(C, axis=0)\n",
    "\n",
    "        #Y = [seed_labels[x] if y >= sim_threshold else exp_labels[x] for x,y in zip(Y_ind, Y_val)]\n",
    "        Y = []\n",
    "        for ii in range(len(Y_ind)):\n",
    "            if(Y_val[ii] >= sim_threshold):\n",
    "                Y.append(seed_labels[Y_ind[ii]])\n",
    "            else:\n",
    "                Y.append(exp_labels[ii])\n",
    "                count2[0] += 1\n",
    "\n",
    "        seed_labels.extend(Y)\n",
    "        seed_TK.extend(exp_TK)\n",
    "\n",
    "    return seed_TK, seed_labels, count2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 40 60 80 100 120 140 160 180 200 220 240 260 280 300 320 340 360 380 400 420 440 460 480 500 520 540 560 580 600 620 640 660 680 700 720 740 760 780 800 820 840 860 880 900 920 940 960 980 1000 1020 1040 1060 1080 1100 1120 1140 1160 1180 1200 1220 1240 1260 1280 1300 1320 1340 1360 1380 1400 1420 1440 1460 1480 1500 1520 1540 1560 1580 1600 1620 1640 1660 1680 1700 1720 1740 1760 1780 1800 1820 1840 1860 1880 1900 "
     ]
    }
   ],
   "source": [
    "X_train_exp_a, y_train_exp_a, count2 = Expand_A(model_2,\n",
    "                                            X_seed.to_list(),\n",
    "                                            y_seed.to_list(),\n",
    "                                            X_expand.to_list(),\n",
    "                                            y_expand.to_list(),\n",
    "                                            20,\n",
    "                                            len(y_expand),\n",
    "                                            20,\n",
    "                                            0.2\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14]\n"
     ]
    }
   ],
   "source": [
    "print(count2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "LR_Normal_a = classify(model_2, LogisticRegression(\n",
    "    random_state=1), X_train_exp_a, y_train_exp_a)\n",
    "# SVM\n",
    "SVM_Normal_a = classify(model_2, svm.SVC(), X_train_exp_a, y_train_exp_a)\n",
    "\n",
    "\n",
    "models_a = []\n",
    "models_a.append(('LR Normal N=2', LR_Normal_a))\n",
    "models_a.append(('SVM Normal N=2', SVM_Normal_a))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Normal N=2\n",
      "0.5888429752066116\n",
      "SVM Normal N=2\n",
      "0.5867768595041323\n"
     ]
    }
   ],
   "source": [
    "file = open('results/output_better_active.txt', 'w+')\n",
    "file.close()\n",
    "\n",
    "outfile = open(\"results/output_better_active.txt\", \"a\")\n",
    "for i, v in models_a:\n",
    "    print(i)\n",
    "    accuracy = metrics.accuracy_score(y_test, v.predict(X_test))\n",
    "    confusion_matrix = metrics.confusion_matrix(y_test, v.predict(X_test))\n",
    "    print('========= {} Model Test Results ==========='.format(i), file=outfile)\n",
    "    print(' ', file=outfile)\n",
    "    print(\"Model Accuracy:\" \"\\n\", accuracy, file=outfile)\n",
    "    print(accuracy)\n",
    "    print(' ', file=outfile)\n",
    "    print(\"Confusion matrix:\" \"\\n\", confusion_matrix, file=outfile)\n",
    "    print(' ', file=outfile)\n",
    "outfile.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expansion Code (Uncertainty Sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Expand_U(model, algorithm, seed_set_TK, seed_set_label, expansion_TK,\n",
    "             expansion_text_labels, batch_size, count, max_threshold):\n",
    "\n",
    "    seed_TK = copy.deepcopy(seed_set_TK)\n",
    "    seed_labels = copy.deepcopy(seed_set_label)\n",
    "    M = np.arange(0, count, batch_size)\n",
    "\n",
    "    # exp_TK_certain will be the list of comments having high proba score\n",
    "    exp_TK_certain = []\n",
    "    exp_TK_certain_labels = []\n",
    "\n",
    "    for i in range(1, len(M)):\n",
    "\n",
    "        print(M[i], end=' ')\n",
    "\n",
    "        exp_TK = expansion_TK[M[i-1]:M[i]]\n",
    "        exp_labels = expansion_text_labels[M[i-1]:M[i]]\n",
    "\n",
    "        # take A as training and B as test and store probs in C\n",
    "        v = classify(model, algorithm, seed_TK, seed_labels)\n",
    "        C = v.predict_proba(exp_TK)\n",
    "        C_abs_diff = [(abs(x[0] - x[1])) for x in C]\n",
    "\n",
    "        # do sorting\n",
    "        # [x for _, x in sorted(zip(Y, X))]\n",
    "        exp_labels = [x for _, x in sorted(zip(C_abs_diff, exp_labels))]\n",
    "        exp_TK = [x for _, x in sorted(zip(C_abs_diff, exp_TK))]\n",
    "        C_sorted = [x for _, x in sorted(zip(C_abs_diff, C))]\n",
    "\n",
    "        Y_uncertain = []\n",
    "        exp_TK_uncertain = []\n",
    "        for j in range(len(C_sorted)):\n",
    "            max_value = max(C_sorted[j])\n",
    "            max_index = str(np.argmax(C_sorted[j]))\n",
    "\n",
    "            if(max_value <= max_threshold):\n",
    "                Y_uncertain.append(max_index)\n",
    "                exp_TK_uncertain.append(exp_TK[j])\n",
    "            else:\n",
    "                exp_TK_certain.append(exp_TK[j])\n",
    "                exp_TK_certain_labels.append(exp_labels[j])\n",
    "\n",
    "        seed_labels.extend(Y_uncertain)\n",
    "        seed_TK.extend(exp_TK_uncertain)\n",
    "\n",
    "    return seed_TK, seed_labels, exp_TK_certain, exp_TK_certain_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 40 60 80 100 120 140 160 180 200 220 240 260 280 300 320 340 360 380 400 420 440 460 480 500 520 540 560 580 600 620 640 660 680 700 720 740 760 780 800 820 840 860 880 900 920 940 960 980 1000 1020 1040 1060 1080 1100 1120 1140 1160 1180 1200 1220 1240 1260 1280 1300 1320 1340 1360 1380 1400 1420 1440 1460 1480 1500 1520 1540 1560 1580 1600 1620 1640 1660 1680 1700 1720 1740 1760 1780 1800 1820 1840 1860 1880 1900 "
     ]
    }
   ],
   "source": [
    "X_train_exp_u, y_train_exp_u, X_certain_exp_u, y_certain_exp_u = Expand_U(model_2,\n",
    "                                                              LogisticRegression(random_state=1),\n",
    "                                                                X_seed.to_list(),\n",
    "                                                                y_seed.to_list(),\n",
    "                                                                X_expand.to_list(),\n",
    "                                                                y_expand.to_list(),\n",
    "                                                                20,\n",
    "                                                                len(y_expand),\n",
    "                                                                0.8\n",
    "                                                                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "LR_Normal_u = classify(model_2, LogisticRegression(\n",
    "    random_state=1), X_train_exp_u, y_train_exp_u)\n",
    "# SVM\n",
    "SVM_Normal_u = classify(model_2, svm.SVC(), X_train_exp_u, y_train_exp_u)\n",
    "\n",
    "models_u = []\n",
    "models_u.append(('LR Normal N=2', LR_Normal_u))\n",
    "models_u.append(('SVM Normal N=2', SVM_Normal_u))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Normal N=2\n",
      "0.5702479338842975\n",
      "SVM Normal N=2\n",
      "0.5723140495867769\n"
     ]
    }
   ],
   "source": [
    "file = open('results/output_better_uncertain.txt', 'w+')\n",
    "file.close()\n",
    "\n",
    "outfile = open(\"results/output_better_uncertain.txt\", \"a\")\n",
    "for i, v in models_u:\n",
    "    print(i)\n",
    "    accuracy = metrics.accuracy_score(y_test, v.predict(X_test))\n",
    "    confusion_matrix = metrics.confusion_matrix(y_test, v.predict(X_test))\n",
    "    print('========= {} Model Test Results ==========='.format(i), file=outfile)\n",
    "    print(' ', file=outfile)\n",
    "    print(\"Model Accuracy:\" \"\\n\", accuracy, file=outfile)\n",
    "    print(accuracy)\n",
    "    print(' ', file=outfile)\n",
    "    print(\"Confusion matrix:\" \"\\n\", confusion_matrix, file=outfile)\n",
    "    print(' ', file=outfile)\n",
    "outfile.close()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ee5cc6fef2d70a7e71ee3826687cbd150f18158e0b1eef11d4f4f92bb920e304"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
