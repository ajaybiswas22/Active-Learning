{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import fasttext\n",
    "import pandas as pd\n",
    "import random\n",
    "from resources.tokTT import CommentTokenizer as CT\n",
    "from resources.basicIO import InputOutput as IO\n",
    "from resources.basicIO import InputOutput as IO\n",
    "from resources.filterLang import FilterLanguage as FL\n",
    "from active_expansion.fasttext_batch_avg import Expander\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import fasttext\n",
    "import pandas as pd\n",
    "from scipy import spatial\n",
    "from scipy.spatial import distance\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "#from sklearn.linear_model import LassoLars\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import copy\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Corpus and Random Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_corpus = IO.load_text('datasets/corpus.txt')\n",
    "tokenized_corpus = CT.cleaned('datasets/corpus.txt')\n",
    "IO.save_text('datasets/tokenized_corpus.txt',tokenized_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Fasttext Unsupervised Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = fasttext.train_unsupervised(input=\"datasets/tokenized_corpus.txt\", lr=0.01, epoch=5, wordNgrams=2, dim=300)\n",
    "model_2.save_model(\"models/ft_unsupervised_N_2.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus\n",
    "df_dict = {'raw_comment': raw_corpus, 'tokenized_comment': tokenized_corpus}\n",
    "df_corpus = pd.DataFrame(df_dict)\n",
    "df_corpus.to_csv('datasets/corpus_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random sample\n",
    "text = IO.load_csv_col('datasets/random_sample.csv', 'comment')\n",
    "text_labels = IO.load_csv_col('datasets/random_sample.csv', 'label')\n",
    "text_labels = list(map(str, map(int, text_labels)))\n",
    "text_TK = [CT.tokenize(x) for x in text]\n",
    "\n",
    "df_dict = {'raw_comment': text, 'tokenized_comment': text_TK, 'label': text_labels}\n",
    "df_sample = pd.DataFrame(df_dict)\n",
    "df_sample.to_csv('datasets/random_sample_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unnecessary comments\n",
    "df_sample = df_sample.drop([x for x in range(len(df_sample)) if int(\n",
    "    df_sample['label'][x]) != 0 and int(df_sample['label'][x]) != 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_comment</th>\n",
       "      <th>tokenized_comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3039</th>\n",
       "      <td>All these farmers are old. How they work in th...</td>\n",
       "      <td>all these farmer be old how they work in there...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3043</th>\n",
       "      <td>Most of these news channels try to show farmer...</td>\n",
       "      <td>most of these news channel try to show farmer ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3046</th>\n",
       "      <td>Or.     2.Those 96%poor farmers who cannot ...</td>\n",
       "      <td>or 2 those 96 poor farmer who can not afford t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3047</th>\n",
       "      <td>Believe me ye video baised thi pro bjp thi inh...</td>\n",
       "      <td>believe me ye video baised thi pro bjp thi inh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3419</th>\n",
       "      <td>We stand with Indian farmers,  down with all o...</td>\n",
       "      <td>we stand with indian farmer down with all oppr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            raw_comment  \\\n",
       "3039  All these farmers are old. How they work in th...   \n",
       "3043  Most of these news channels try to show farmer...   \n",
       "3046     Or.     2.Those 96%poor farmers who cannot ...   \n",
       "3047  Believe me ye video baised thi pro bjp thi inh...   \n",
       "3419  We stand with Indian farmers,  down with all o...   \n",
       "\n",
       "                                      tokenized_comment label  \n",
       "3039  all these farmer be old how they work in there...     1  \n",
       "3043  most of these news channel try to show farmer ...     1  \n",
       "3046  or 2 those 96 poor farmer who can not afford t...     0  \n",
       "3047  believe me ye video baised thi pro bjp thi inh...     1  \n",
       "3419  we stand with indian farmer down with all oppr...     0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1259\n",
       "1     939\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_sample['tokenized_comment'], \n",
    "                                                    df_sample['label'], test_size=0.2, \n",
    "                                                    random_state=42,\n",
    "                                                    stratify=df_sample['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  1758\n",
      "X_test:  440\n"
     ]
    }
   ],
   "source": [
    "print('X_train: ' ,len(X_train))\n",
    "print('X_test: ' ,len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FastTextTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\" Convert texts into their mean fastText vectors \"\"\"\n",
    "\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.stack([np.mean([self.model[w] for w in text.split()], 0) for text in X])\n",
    "\n",
    "\n",
    "def classify(small_model, predictor, lines, Y):\n",
    "    classifier = make_pipeline(\n",
    "        FastTextTransformer(model=small_model),\n",
    "        predictor\n",
    "    ).fit(\n",
    "        lines,\n",
    "        Y\n",
    "    )\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "LR_Normal = classify(model_2, LogisticRegression(random_state=1), X_train, y_train)\n",
    "# SVM\n",
    "SVM_Normal = classify(model_2, svm.SVC(), X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(('LR Normal N=2', LR_Normal))\n",
    "models.append(('SVM Normal N=2', SVM_Normal))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Normal N=2\n",
      "0.5727272727272728\n",
      "SVM Normal N=2\n",
      "0.5727272727272728\n"
     ]
    }
   ],
   "source": [
    "file = open('results/output_better.txt', 'w+')\n",
    "file.close()\n",
    "\n",
    "outfile = open(\"results/output_better.txt\", \"a\")\n",
    "for i, v in models:\n",
    "    print(i)\n",
    "    accuracy = metrics.accuracy_score(y_test, v.predict(X_test))\n",
    "    confusion_matrix = metrics.confusion_matrix(y_test, v.predict(X_test))\n",
    "    print('========= {} Model Test Results ==========='.format(i), file=outfile)\n",
    "    print(' ', file=outfile)\n",
    "    print(\"Model Accuracy:\" \"\\n\", accuracy, file=outfile)\n",
    "    print(accuracy)\n",
    "    print(' ', file=outfile)\n",
    "    print(\"Confusion matrix:\" \"\\n\", confusion_matrix, file=outfile)\n",
    "    print(' ', file=outfile)\n",
    "outfile.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('clf', LogisticRegression(random_state=1)),\n",
    "                    ])\n",
    "text_clf = text_clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7613636363636364"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = text_clf.predict(X_test)\n",
    "np.mean(predicted == y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.73 (+/- 0.07)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(text_clf, df_sample.tokenized_comment, df_sample.label, cv=10)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seed Set + AVG + Batch + Random Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_seed, X_expand, y_seed, y_expand = train_test_split(X_train,\n",
    "                                                    y_train, test_size=0.87,\n",
    "                                                    random_state=41,\n",
    "                                                    stratify=y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_seed:  228\n",
      "X_expand:  1530\n"
     ]
    }
   ],
   "source": [
    "print('X_seed: ',len(X_seed))\n",
    "print('X_expand: ',len(X_expand))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(model, line, k):\n",
    "    # words contains all the words in the corpus\n",
    "    lst1 = model.get_nearest_neighbors(line, k)\n",
    "    v1 = []\n",
    "    l1 = [x[1] for x in lst1]\n",
    "    l10 = [x[0] for x in lst1]\n",
    "    for i in range(len(model.words)):\n",
    "        try:\n",
    "            v1.append(l10[l1.index(model.words[i])])\n",
    "        except:\n",
    "            v1.append(0)\n",
    "    return v1\n",
    "\n",
    "def cos_sim(model,l1,l2,k):\n",
    "    NN_l1 = score(model, l1, k)\n",
    "    NN_l2 = score(model, l2, k)\n",
    "    return 1-scipy.spatial.distance.cosine(NN_l1, NN_l2)\n",
    "\n",
    "def sim(model, x, y, k, sim_type):\n",
    "    if(sim_type == 'cosine_sim'):\n",
    "        return cos_sim(model, x, y, k)\n",
    "\n",
    "def sim_matrix(model, A, B, k, sim_type):\n",
    "    m = len(A)\n",
    "    n = len(B)\n",
    "    C = np.zeros((m, n))\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            C[i][j] = sim(model, A[i], B[j], k, sim_type)\n",
    "    return C\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expansion Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Expand(model, seed_set_TK, seed_set_label, expansion_TK, expansion_text_labels, batch_size, count, k, random_rate):\n",
    "    seed_TK = copy.deepcopy(seed_set_TK)\n",
    "    seed_labels = copy.deepcopy(seed_set_label)\n",
    "    M = np.arange(0, count, batch_size)\n",
    "    cnt = int(random_rate * batch_size)\n",
    "    count2 = [0]\n",
    "\n",
    "    for i in range(1, len(M)):\n",
    "\n",
    "        exp_TK = expansion_TK[M[i-1]:M[i]]\n",
    "        exp_labels = expansion_text_labels[M[i-1]:M[i]]\n",
    "\n",
    "        C = sim_matrix(model, seed_TK, exp_TK, k, 'cosine_sim')\n",
    "        Y_ind = np.argmax(C, axis=0)\n",
    "        Y = [seed_labels[x] for x in Y_ind]\n",
    "\n",
    "        seed_labels.extend(Y)\n",
    "        seed_TK.extend(exp_TK)\n",
    "\n",
    "    return seed_TK, seed_labels, count2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\AJAYBI~1\\AppData\\Local\\Temp/ipykernel_32276/1085117934.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(model, line, k)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m             \u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml10\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: 'ease' is not in list",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\AJAYBI~1\\AppData\\Local\\Temp/ipykernel_32276/735230989.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m X_train_exp, y_train_exp = Expand(model_2, \n\u001b[0m\u001b[0;32m      2\u001b[0m                                   \u001b[0mX_seed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                   \u001b[0my_seed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                                   \u001b[0mX_expand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                   \u001b[0my_expand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\AJAYBI~1\\AppData\\Local\\Temp/ipykernel_32276/1460950509.py\u001b[0m in \u001b[0;36mExpand\u001b[1;34m(model, seed_set_TK, seed_set_label, expansion_TK, expansion_text_labels, batch_size, count, k, random_rate)\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mexp_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexpansion_text_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msim_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed_TK\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexp_TK\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'cosine_sim'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mY_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mseed_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mY_ind\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\AJAYBI~1\\AppData\\Local\\Temp/ipykernel_32276/1085117934.py\u001b[0m in \u001b[0;36msim_matrix\u001b[1;34m(model, A, B, k, sim_type)\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m             \u001b[0mC\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mB\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msim_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\AJAYBI~1\\AppData\\Local\\Temp/ipykernel_32276/1085117934.py\u001b[0m in \u001b[0;36msim\u001b[1;34m(model, x, y, k, sim_type)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msim_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msim_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'cosine_sim'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcos_sim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msim_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mB\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msim_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\AJAYBI~1\\AppData\\Local\\Temp/ipykernel_32276/1085117934.py\u001b[0m in \u001b[0;36mcos_sim\u001b[1;34m(model, l1, l2, k)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcos_sim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ml1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ml2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mNN_l1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mNN_l2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspatial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcosine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNN_l1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNN_l2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\AJAYBI~1\\AppData\\Local\\Temp/ipykernel_32276/1085117934.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(model, line, k)\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml10\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m             \u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mv1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_train_exp, y_train_exp, count2 = Expand(model_2, \n",
    "                                  X_seed.to_list(), \n",
    "                                  y_seed.to_list(), \n",
    "                                  X_expand.to_list(), \n",
    "                                  y_expand.to_list(),\n",
    "                                  100,\n",
    "                                  len(y_expand),\n",
    "                                  20,\n",
    "                                  0.1\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "LR_Normal_e = classify(model_2, LogisticRegression(\n",
    "    random_state=1), X_train_exp, y_train_exp)\n",
    "# SVM\n",
    "SVM_Normal_e = classify(model_2, svm.SVC(), X_train_exp, y_train_exp)\n",
    "\n",
    "\n",
    "models_e = []\n",
    "models_e.append(('LR Normal N=2', LR_Normal_e))\n",
    "models_e.append(('SVM Normal N=2', SVM_Normal_e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('results/output_better_exp.txt', 'w+')\n",
    "file.close()\n",
    "\n",
    "outfile = open(\"results/output_better_exp.txt\", \"a\")\n",
    "for i, v in models_e:\n",
    "    print(i)\n",
    "    accuracy = metrics.accuracy_score(y_test, v.predict(X_test))\n",
    "    confusion_matrix = metrics.confusion_matrix(y_test, v.predict(X_test))\n",
    "    print('========= {} Model Test Results ==========='.format(i), file=outfile)\n",
    "    print(' ', file=outfile)\n",
    "    print(\"Model Accuracy:\" \"\\n\", accuracy, file=outfile)\n",
    "    print(accuracy)\n",
    "    print(' ', file=outfile)\n",
    "    print(\"Confusion matrix:\" \"\\n\", confusion_matrix, file=outfile)\n",
    "    print(' ', file=outfile)\n",
    "outfile.close()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ee5cc6fef2d70a7e71ee3826687cbd150f18158e0b1eef11d4f4f92bb920e304"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
