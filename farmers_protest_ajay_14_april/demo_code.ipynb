{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\AJAY\n",
      "[nltk_data]     BISWAS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import fasttext\n",
    "import pandas as pd\n",
    "import random\n",
    "from resources.tokTT import CommentTokenizer as CT\n",
    "from resources.basicIO import InputOutput as IO\n",
    "from resources.basicIO import InputOutput as IO\n",
    "from resources.filterLang import FilterLanguage as FL\n",
    "from active_expansion.fasttext_batch_avg import Expander\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import fasttext\n",
    "import pandas as pd\n",
    "from scipy import spatial\n",
    "from scipy.spatial import distance\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "#from sklearn.linear_model import LassoLars\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import copy\n",
    "import scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(model, line, k):\n",
    "    # words contains all the words in the corpus\n",
    "    lst1 = model.get_nearest_neighbors(line, k)\n",
    "    v1 = []\n",
    "    l1 = [x[1] for x in lst1]\n",
    "    l10 = [x[0] for x in lst1]\n",
    "    for i in range(len(model.words)):\n",
    "        try:\n",
    "            v1.append(l10[l1.index(model.words[i])])\n",
    "        except:\n",
    "            v1.append(0)\n",
    "    return v1\n",
    "\n",
    "\n",
    "def cos_sim(model, l1, l2, k):\n",
    "    a = score(model, l1, k)\n",
    "    b = score(model, l2, k)\n",
    "    \n",
    "    dot_product = np.dot(a, b)\n",
    "    norm_a = np.linalg.norm(a)\n",
    "    norm_b = np.linalg.norm(b)\n",
    "\n",
    "    if(norm_a * norm_b == 0.0):\n",
    "        return dot_product / (norm_a * norm_b + 0.001)\n",
    "\n",
    "    return dot_product / (norm_a * norm_b)\n",
    "\n",
    "\n",
    "def sim(model, x, y, k, sim_type):\n",
    "    if(sim_type == 'cosine_sim'):\n",
    "        return cos_sim(model, x, y, k)\n",
    "\n",
    "\n",
    "def sim_matrix(model, A, B, k, sim_type):\n",
    "    m = len(A)\n",
    "    n = len(B)\n",
    "    C = np.zeros((m, n))\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            C[i][j] = sim(model, A[i], B[j], k, sim_type)\n",
    "    return C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Expand(model, seed_set_TK, seed_set_label, expansion_TK, expansion_text_labels, batch_size, count, k, random_rate):\n",
    "    seed_TK = copy.deepcopy(seed_set_TK)\n",
    "    seed_labels = copy.deepcopy(seed_set_label)\n",
    "    M = np.arange(0, count, batch_size)\n",
    "    cnt = int(random_rate * batch_size)\n",
    "    count2 = [0]\n",
    "    print(M)\n",
    "\n",
    "    for i in range(1, len(M)):\n",
    "\n",
    "        exp_TK = expansion_TK[M[i-1]:M[i]]\n",
    "        exp_labels = expansion_text_labels[M[i-1]:M[i]]\n",
    "\n",
    "        C = sim_matrix(model, seed_TK, exp_TK, k, 'cosine_sim')\n",
    "        Y_ind = np.argmax(C, axis=0)\n",
    "        Y = [seed_labels[x] for x in Y_ind]\n",
    "\n",
    "        seed_labels.extend(Y)\n",
    "        seed_TK.extend(exp_TK)\n",
    "\n",
    "    return seed_TK, seed_labels, count2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "model_N_2 = fasttext.load_model('models/ft_unsupervised_N_2.bin')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = ['I support farmers', 'I am proud of farmers', 'i hate farmers', 'i want farm bills']\n",
    "A_y = [0,0,1,1]\n",
    "B = ['I am support farm bill', 'I love farmers', 'they are not farmers', 'farm bills are good']\n",
    "B_y = [1,0,1,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2]\n"
     ]
    }
   ],
   "source": [
    "X_train_exp, y_train_exp, count2 = Expand(model_N_2,\n",
    "                                  A,\n",
    "                                  A_y,\n",
    "                                  B,\n",
    "                                  B_y,\n",
    "                                  2,\n",
    "                                  len(B_y),\n",
    "                                  20,\n",
    "                                  0.1\n",
    "                                  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 1, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_train_exp)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ee5cc6fef2d70a7e71ee3826687cbd150f18158e0b1eef11d4f4f92bb920e304"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
