{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resources.filterLang import FilterLanguage as FL\n",
    "from resources.tokTT import CommentTokenizer as CT \n",
    "import fasttext\n",
    "import numpy as np\n",
    "from resources.basicIO import InputOutput as IO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN(model, line, K):\n",
    "    return model.get_nearest_neighbors(line, k=K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finds similarity score \n",
    "def score(model, line,k=10):\n",
    "    # words contains all the words in the corpus\n",
    "    lst1 = NN(model, line, k)\n",
    "    v1 = []\n",
    "    l1 = [x[1] for x in lst1]\n",
    "    l10 = [x[0] for x in lst1]\n",
    "    for i in range(len(model.words)):\n",
    "        try:\n",
    "            v1.append(l10[l1.index(model.words[i])])\n",
    "        except:\n",
    "            v1.append(0)\n",
    "    return v1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(a, b):\n",
    "\tdot_product = np.dot(a, b)\n",
    "\tnorm_a = np.linalg.norm(a)\n",
    "\tnorm_b = np.linalg.norm(b)\n",
    "\treturn dot_product / (norm_a * norm_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim(x,y,sim_type='cosine_sim'):\n",
    "\n",
    "    if(sim_type == 'cosine_sim'):\n",
    "        return cos_sim(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find similarity score matrix between A and B\n",
    "# pass transpose of B\n",
    "def sim_matrix(A,B,sim_type):\n",
    "    m,p = A.shape\n",
    "    p,n = B.shape\n",
    "    C = np.zeros((m,n))\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            C[i][j] = sim(A[i,:], B[:,j],sim_type)\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finds classwise average and returns an array of predicted\n",
    "# class labels. labels are classwise labels in ascending order\n",
    "def label_avg(X,labels):\n",
    "\n",
    "    m,n = X.shape\n",
    "    if(m != len(labels)):\n",
    "        return None\n",
    "\n",
    "    avg_sums = [] \n",
    "    no_labels = len(list(set(labels)))\n",
    "\n",
    "    for p in range(n):\n",
    "\n",
    "        column = X[:, p]\n",
    "\n",
    "        avgs = np.zeros(no_labels)\n",
    "\n",
    "        for lbl in range(no_labels):\n",
    "            indices = [ix for ix, label in enumerate(labels) if label == lbl]\n",
    "            avgs[lbl] = np.mean([column[x] for x in indices])\n",
    "    \n",
    "        max_avg_pos = avgs.argmax()\n",
    "        avg_sums.append(max_avg_pos)\n",
    "\n",
    "    return avg_sums\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "model_N_2 = fasttext.load_model('models/ft_unsupervised_N_2.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading 60 comments\n",
    "expansion_text = IO.load_csv_col('datasets/random_sample.csv','comment')\n",
    "expansion_text = expansion_text[0:60]\n",
    "expansion_text_labels = IO.load_csv_col('datasets/random_sample.csv','label')\n",
    "expansion_text_labels = list(map(str,map(int,expansion_text_labels[0:60])))\n",
    "seed_set_text = IO.load_text('datasets/seed_set.txt')\n",
    "seed_set_labels = IO.load_text('datasets/seed_set_labels.txt')\n",
    "seed_set_labels = list(map(int, seed_set_labels[0:60]))\n",
    "seed_set_TK = CT.cleaned('datasets/seed_set.txt')\n",
    "expansion_TK = [CT.tokenize(x) for x in expansion_text]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_seed = []\n",
    "i = 0\n",
    "for line in seed_set_TK:\n",
    "    score_seed.append(score(model_N_2, line, 20))\n",
    "    i += 1\n",
    "    if(i == 60):\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_ex = []\n",
    "i=0\n",
    "for line in expansion_TK:\n",
    "    score_ex.append(score(model_N_2,line,50))\n",
    "    i+=1\n",
    "    if(i==60):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array(score_seed)\n",
    "B = np.array(score_ex).T\n",
    "C = sim_matrix(A,B,'cosine_sim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "Y = label_avg(C,seed_set_labels)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ee5cc6fef2d70a7e71ee3826687cbd150f18158e0b1eef11d4f4f92bb920e304"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
