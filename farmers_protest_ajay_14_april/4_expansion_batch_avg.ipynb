{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resources.filterLang import FilterLanguage as FL\n",
    "from resources.tokTT import CommentTokenizer as CT\n",
    "import fasttext\n",
    "import numpy as np\n",
    "from resources.basicIO import InputOutput as IO\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' def shuffleListsTogether(listA, listB):\\n    zipped = list(zip(listA, listB))\\n    np.random.shuffle(zipped)\\n    listA, listB = zip(*zipped)\\n    return list(listA), list(listB) '"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" def shuffleListsTogether(listA, listB):\n",
    "    zipped = list(zip(listA, listB))\n",
    "    np.random.shuffle(zipped)\n",
    "    listA, listB = zip(*zipped)\n",
    "    return list(listA), list(listB) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN(model, line, K):\n",
    "    return model.get_nearest_neighbors(line, k=K)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oracleHelp(classdata):\n",
    "    False\n",
    "    sums = sum(classdata)\n",
    "    if(sums == 0):\n",
    "        return False\n",
    "    res = any(((ele/sums) >= 0.48 and (ele/sums) <= 0.52) for ele in classdata)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(a, b):\n",
    "\tdot_product = np.dot(a, b)\n",
    "\tnorm_a = np.linalg.norm(a)\n",
    "\tnorm_b = np.linalg.norm(b)\n",
    "\treturn dot_product / (norm_a * norm_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim(x,y,sim_type='cosine_sim'):\n",
    "\n",
    "    if(sim_type == 'cosine_sim'):\n",
    "        return cos_sim(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find similarity score matrix between A and B\n",
    "# pass transpose of B\n",
    "def sim_matrix(A, B, sim_type):\n",
    "    m, p = A.shape\n",
    "    p, n = B.shape\n",
    "    C = np.zeros((m, n))\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            C[i][j] = sim(A[i, :], B[:, j], sim_type)\n",
    "    return C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finds similarity score\n",
    "def score(model, line, k=10):\n",
    "    # words contains all the words in the corpus\n",
    "    lst1 = NN(model, line, k)\n",
    "    v1 = []\n",
    "    l1 = [x[1] for x in lst1]\n",
    "    l10 = [x[0] for x in lst1]\n",
    "    for i in range(len(model.words)):\n",
    "        try:\n",
    "            v1.append(l10[l1.index(model.words[i])])\n",
    "        except:\n",
    "            v1.append(0)\n",
    "    return v1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finds classwise average and returns an array of predicted\n",
    "# class labels. labels are classwise labels in ascending order\n",
    "def label_avg(X, labels,count,exp_labels=None):\n",
    "\n",
    "    m, n = X.shape\n",
    "    if(m != len(labels)):\n",
    "        return None\n",
    "\n",
    "    avg_sums = []\n",
    "    no_labels = len(list(set(labels)))\n",
    "\n",
    "    for p in range(n):\n",
    "\n",
    "        column = X[:, p]\n",
    "\n",
    "        avgs = np.zeros(no_labels)\n",
    "\n",
    "        for lbl in range(no_labels):\n",
    "            indices = [ix for ix, label in enumerate(labels) if int(label) == lbl]\n",
    "            avgs[lbl] = np.mean([column[x] for x in indices])\n",
    "\n",
    "        if(exp_labels != None and oracleHelp(avgs)):\n",
    "            avg_sums.append(exp_labels[p])\n",
    "            print('Y,', exp_labels[p], ',', exp_labels[p])\n",
    "            count[0]+=1\n",
    "        else:\n",
    "            max_avg_pos = avgs.argmax()\n",
    "            avg_sums.append(max_avg_pos)\n",
    "            print('N,' , max_avg_pos, ',', exp_labels[p])\n",
    "\n",
    "    return avg_sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_NN(model,lines_TK,k):\n",
    "    scores = []\n",
    "    for line in lines_TK:\n",
    "        scores.append(score(model, line, k))\n",
    "\n",
    "    return scores  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "model_N_2 = fasttext.load_model('models/ft_unsupervised_N_2.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load comments, seedset, labels of bobth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading 60 comments\n",
    "expansion_text = IO.load_csv_col('datasets/random_sample.csv', 'comment')\n",
    "expansion_text = expansion_text[0:350]\n",
    "expansion_text_labels = IO.load_csv_col('datasets/random_sample.csv', 'label')\n",
    "expansion_text_labels = list(map(int, expansion_text_labels[0:350]))\n",
    "seed_set_text = IO.load_text('datasets/seed_set.txt')\n",
    "seed_set_labels = IO.load_text('datasets/seed_set_labels.txt')\n",
    "seed_set_labels = list(map(int, seed_set_labels))\n",
    "seed_set_TK = CT.cleaned('datasets/seed_set.txt')\n",
    "expansion_TK = [CT.tokenize(x) for x in expansion_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N, 0 , 0\n",
      "N, 0 , 0\n",
      "N, 0 , 1\n",
      "N, 0 , 0\n",
      "N, 0 , 0\n",
      "N, 1 , 0\n",
      "N, 1 , 0\n",
      "N, 1 , 1\n",
      "N, 0 , 0\n",
      "N, 0 , 0\n",
      "N, 1 , 0\n",
      "N, 0 , 0\n",
      "N, 0 , 0\n",
      "N, 0 , 1\n",
      "N, 0 , 0\n",
      "N, 0 , 0\n",
      "N, 0 , 1\n",
      "N, 0 , 0\n",
      "N, 0 , 0\n",
      "N, 0 , 0\n",
      "N, 0 , 0\n",
      "N, 0 , 0\n",
      "N, 1 , 1\n",
      "N, 0 , 0\n",
      "N, 0 , 0\n",
      "N, 0 , 0\n",
      "N, 0 , 0\n",
      "N, 0 , 0\n",
      "N, 1 , 0\n",
      "N, 1 , 0\n",
      "N, 1 , 0\n",
      "N, 0 , 1\n",
      "N, 0 , 0\n",
      "N, 1 , 0\n",
      "N, 0 , 0\n",
      "N, 1 , 1\n",
      "N, 0 , 0\n",
      "N, 0 , 0\n",
      "N, 0 , 0\n",
      "N, 1 , 1\n",
      "N, 0 , 0\n",
      "N, 0 , 0\n",
      "N, 0 , 0\n",
      "N, 0 , 0\n",
      "N, 0 , 0\n",
      "N, 0 , 0\n",
      "N, 0 , 0\n",
      "N, 0 , 1\n",
      "N, 0 , 0\n",
      "N, 1 , 0\n",
      "N, 0 , 0\n",
      "N, 0 , 1\n",
      "N, 0 , 0\n",
      "N, 0 , 0\n",
      "N, 0 , 1\n",
      "N, 0 , 1\n",
      "N, 0 , 0\n",
      "N, 0 , 0\n",
      "N, 0 , 0\n",
      "N, 0 , 0\n",
      "N, 0 , 1\n",
      "N, 1 , 1\n",
      "N, 0 , 0\n",
      "N, 0 , 0\n",
      "N, 0 , 0\n",
      "N, 0 , 1\n",
      "N, 0 , 1\n",
      "N, 1 , 1\n",
      "N, 1 , 1\n",
      "N, 1 , 1\n",
      "N, 1 , 0\n",
      "N, 1 , 0\n",
      "N, 0 , 1\n",
      "N, 0 , 0\n",
      "N, 0 , 0\n",
      "Y, 0 , 0\n",
      "N, 1 , 1\n",
      "N, 0 , 0\n",
      "N, 1 , 1\n",
      "N, 0 , 0\n",
      "N, 1 , 0\n",
      "N, 1 , 1\n",
      "N, 0 , 1\n",
      "N, 0 , 0\n",
      "N, 1 , 1\n",
      "N, 0 , 0\n",
      "N, 1 , 1\n",
      "N, 1 , 0\n",
      "N, 0 , 0\n",
      "N, 1 , 1\n",
      "N, 0 , 1\n",
      "N, 0 , 1\n",
      "N, 1 , 1\n",
      "N, 1 , 1\n",
      "N, 0 , 0\n",
      "N, 1 , 1\n",
      "N, 1 , 0\n",
      "N, 0 , 0\n",
      "N, 0 , 1\n",
      "N, 0 , 0\n",
      "N, 0 , 1\n",
      "N, 0 , 0\n",
      "N, 0 , 1\n",
      "N, 0 , 1\n",
      "N, 1 , 1\n",
      "N, 0 , 0\n",
      "N, 1 , 0\n",
      "N, 0 , 0\n",
      "N, 0 , 1\n",
      "N, 0 , 1\n",
      "N, 0 , 0\n",
      "N, 1 , 1\n",
      "N, 1 , 1\n",
      "N, 1 , 1\n",
      "Y, 0 , 0\n",
      "N, 1 , 1\n",
      "N, 0 , 0\n",
      "N, 0 , 0\n",
      "N, 0 , 0\n",
      "N, 0 , 0\n",
      "N, 0 , 0\n",
      "N, 1 , 0\n",
      "N, 0 , 0\n",
      "N, 1 , 0\n",
      "N, 0 , 0\n",
      "N, 0 , 0\n",
      "N, 0 , 0\n",
      "N, 1 , 0\n",
      "N, 1 , 0\n",
      "N, 0 , 0\n",
      "N, 1 , 0\n",
      "N, 0 , 0\n",
      "N, 1 , 0\n",
      "N, 0 , 0\n",
      "N, 1 , 0\n",
      "N, 1 , 0\n",
      "N, 0 , 1\n",
      "N, 0 , 1\n",
      "N, 1 , 0\n",
      "N, 1 , 0\n",
      "N, 0 , 0\n",
      "N, 1 , 1\n",
      "N, 0 , 1\n",
      "N, 1 , 1\n",
      "N, 1 , 0\n",
      "N, 1 , 1\n",
      "N, 0 , 0\n",
      "N, 0 , 1\n",
      "N, 0 , 1\n",
      "N, 0 , 0\n",
      "N, 1 , 0\n",
      "N, 1 , 1\n",
      "N, 1 , 0\n",
      "N, 0 , 0\n",
      "N, 1 , 1\n",
      "N, 1 , 1\n",
      "N, 0 , 1\n",
      "N, 0 , 1\n",
      "N, 1 , 1\n",
      "N, 0 , 0\n",
      "N, 0 , 1\n",
      "N, 1 , 1\n",
      "N, 1 , 0\n",
      "N, 0 , 1\n",
      "N, 0 , 1\n",
      "N, 1 , 1\n",
      "N, 0 , 0\n",
      "N, 0 , 0\n",
      "N, 0 , 1\n",
      "N, 1 , 1\n",
      "N, 1 , 1\n",
      "N, 0 , 0\n",
      "N, 1 , 1\n",
      "N, 0 , 0\n",
      "N, 0 , 1\n",
      "N, 1 , 0\n",
      "N, 0 , 1\n",
      "N, 0 , 0\n",
      "N, 0 , 0\n",
      "N, 0 , 0\n",
      "N, 0 , 1\n",
      "N, 0 , 0\n",
      "N, 1 , 0\n",
      "N, 0 , 0\n",
      "N, 1 , 1\n",
      "N, 0 , 1\n",
      "N, 1 , 0\n",
      "N, 0 , 1\n",
      "N, 0 , 1\n",
      "N, 0 , 0\n",
      "N, 0 , 0\n",
      "N, 0 , 1\n",
      "N, 1 , 0\n",
      "N, 1 , 1\n",
      "N, 0 , 0\n",
      "N, 0 , 1\n",
      "N, 0 , 0\n",
      "N, 0 , 0\n",
      "N, 1 , 0\n",
      "N, 1 , 0\n",
      "N, 0 , 1\n",
      "N, 0 , 1\n",
      "N, 0 , 1\n",
      "N, 0 , 1\n",
      "N, 1 , 0\n",
      "N, 0 , 1\n",
      "N, 0 , 0\n",
      "N, 1 , 0\n",
      "N, 0 , 1\n",
      "N, 0 , 0\n",
      "N, 0 , 1\n",
      "N, 1 , 0\n",
      "N, 1 , 1\n",
      "N, 1 , 0\n",
      "N, 1 , 0\n",
      "N, 0 , 0\n",
      "N, 0 , 1\n",
      "N, 0 , 1\n",
      "N, 0 , 1\n",
      "N, 1 , 1\n",
      "N, 1 , 0\n",
      "N, 0 , 0\n",
      "N, 1 , 0\n",
      "N, 0 , 0\n",
      "N, 1 , 0\n",
      "N, 0 , 1\n",
      "N, 0 , 0\n",
      "N, 0 , 0\n",
      "N, 0 , 1\n",
      "N, 0 , 1\n",
      "N, 0 , 0\n",
      "N, 0 , 1\n",
      "N, 0 , 0\n",
      "N, 1 , 0\n",
      "N, 0 , 1\n",
      "N, 0 , 1\n",
      "N, 0 , 1\n",
      "N, 0 , 1\n",
      "N, 0 , 0\n",
      "N, 0 , 1\n",
      "N, 0 , 1\n",
      "N, 1 , 1\n",
      "N, 0 , 0\n",
      "N, 0 , 1\n",
      "Y, 1 , 1\n",
      "N, 0 , 0\n",
      "N, 0 , 0\n",
      "Y, 1 , 1\n",
      "N, 0 , 1\n",
      "N, 1 , 1\n",
      "N, 1 , 1\n",
      "N, 0 , 0\n",
      "N, 0 , 0\n",
      "N, 0 , 1\n",
      "N, 0 , 0\n",
      "N, 1 , 1\n",
      "N, 0 , 1\n",
      "N, 0 , 0\n",
      "N, 0 , 0\n",
      "N, 1 , 0\n",
      "N, 0 , 0\n",
      "N, 0 , 0\n",
      "N, 1 , 0\n",
      "N, 1 , 1\n",
      "N, 1 , 0\n",
      "N, 1 , 0\n",
      "N, 0 , 0\n",
      "N, 1 , 1\n",
      "N, 1 , 1\n",
      "N, 1 , 1\n",
      "N, 0 , 1\n",
      "N, 0 , 0\n",
      "N, 0 , 0\n",
      "N, 1 , 1\n",
      "N, 1 , 1\n",
      "N, 0 , 0\n",
      "N, 0 , 1\n",
      "N, 0 , 0\n",
      "N, 1 , 1\n",
      "N, 1 , 1\n",
      "N, 1 , 0\n",
      "N, 0 , 0\n",
      "N, 0 , 1\n",
      "N, 0 , 0\n",
      "N, 0 , 0\n",
      "N, 1 , 0\n",
      "N, 0 , 1\n",
      "N, 1 , 1\n",
      "N, 0 , 0\n",
      "N, 1 , 1\n",
      "N, 1 , 1\n",
      "N, 1 , 0\n",
      "N, 1 , 0\n",
      "N, 0 , 0\n",
      "N, 0 , 0\n",
      "N, 0 , 1\n",
      "N, 1 , 0\n",
      "N, 0 , 1\n",
      "N, 1 , 1\n",
      "N, 0 , 0\n",
      "N, 0 , 1\n",
      "N, 1 , 1\n",
      "N, 0 , 1\n",
      "N, 0 , 0\n",
      "N, 0 , 1\n",
      "N, 1 , 1\n",
      "N, 0 , 1\n",
      "N, 1 , 0\n",
      "N, 0 , 1\n",
      "N, 0 , 1\n",
      "N, 1 , 0\n",
      "N, 0 , 1\n",
      "N, 0 , 0\n",
      "N, 0 , 1\n",
      "N, 0 , 1\n",
      "N, 0 , 0\n",
      "N, 0 , 1\n",
      "N, 1 , 0\n",
      "N, 0 , 1\n",
      "N, 0 , 0\n",
      "N, 0 , 1\n",
      "N, 0 , 0\n",
      "N, 1 , 0\n",
      "N, 0 , 1\n",
      "N, 1 , 0\n",
      "N, 0 , 1\n",
      "N, 0 , 0\n",
      "N, 1 , 1\n",
      "N, 0 , 1\n",
      "N, 0 , 1\n",
      "N, 0 , 1\n",
      "N, 0 , 0\n",
      "N, 0 , 1\n",
      "N, 0 , 1\n",
      "N, 0 , 1\n",
      "N, 1 , 1\n",
      "N, 0 , 1\n",
      "N, 1 , 1\n",
      "N, 1 , 0\n",
      "N, 1 , 1\n"
     ]
    }
   ],
   "source": [
    "# select comments from expansion_set in batches\n",
    "batch_size = 10\n",
    "k = 20\n",
    "\n",
    "M = np.arange(0,350,batch_size)\n",
    "\n",
    "seed_TK = copy.deepcopy(seed_set_TK)\n",
    "seed_labels = copy.deepcopy(seed_set_labels)\n",
    "seed_text = copy.deepcopy(seed_set_text)\n",
    "\n",
    "count2 = [0]\n",
    "for i in range(1, len(M)):\n",
    "    \n",
    "    exp_TK = expansion_TK[M[i-1]:M[i]]\n",
    "    exp_labels = expansion_text_labels[M[i-1]:M[i]]\n",
    "\n",
    "    # find NN\n",
    "    seed_NN = get_NN(model_N_2,seed_TK,k)\n",
    "    exp_NN = get_NN(model_N_2,exp_TK,k)\n",
    "\n",
    "    A = np.array(seed_NN)\n",
    "    B = np.array(exp_NN).T\n",
    "    C = sim_matrix(A,B,'cosine_sim')\n",
    "    Y = label_avg(C, seed_labels, count2, exp_labels)\n",
    "    seed_labels += Y\n",
    "    seed_TK += exp_TK\n",
    "    seed_text += expansion_text[M[i-1]:M[i]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "IO.save_text('datasets_post/batch_N_2.txt', seed_text)\n",
    "IO.save_text('datasets_post/batch_labels_N_2.txt',map(str, seed_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4]\n"
     ]
    }
   ],
   "source": [
    "print(count2)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ee5cc6fef2d70a7e71ee3826687cbd150f18158e0b1eef11d4f4f92bb920e304"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
