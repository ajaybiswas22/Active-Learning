{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import fasttext\n",
    "import pandas as pd\n",
    "from scipy import spatial\n",
    "from scipy.spatial import distance\n",
    "from resources.basicIO import InputOutput as IO\n",
    "from resources.tokTT import CommentTokenizer\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FastTextTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\" Convert texts into their mean fastText vectors \"\"\"\n",
    "\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.stack([\n",
    "            np.mean([self.model[w] for w in text.split()], 0)\n",
    "            for text in X\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(small_model,predictor,lines,Y):\n",
    "    classifier = make_pipeline(\n",
    "        FastTextTransformer(model=small_model),\n",
    "        predictor\n",
    "    ).fit(\n",
    "        lines,\n",
    "        Y\n",
    "    )\n",
    "    return classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "# load models\n",
    "model_N_2 = fasttext.load_model('models/ft_unsupervised_N_2.bin')\n",
    "model_N_3 = fasttext.load_model('models/ft_unsupervised_N_3.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load seed set and tokenize\n",
    "seed_set = CommentTokenizer.cleaned(\"datasets/seed_set.txt\")\n",
    "# Load seed Labels\n",
    "Y = IO.load_nums(\"datasets/seed_set_labels.txt\")\n",
    "\n",
    "# Load expanded seed set\n",
    "seed_set_expanded_N_2 = CommentTokenizer.cleaned(\"datasets_post/seed_set_expanded_N_2.txt\")\n",
    "Y_N_2 = IO.load_nums(\"datasets_post/seed_set_expanded_labels_N_2.txt\")\n",
    "\n",
    "seed_set_expanded_N_3 = CommentTokenizer.cleaned(\"datasets_post/seed_set_expanded_N_3.txt\")\n",
    "Y_N_3 = IO.load_nums(\"datasets_post/seed_set_expanded_labels_N_3.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load testing set\n",
    "testing_text = IO.load_csv_col('datasets/random_sample.csv', 'comment')\n",
    "testing_text = testing_text[100:200]\n",
    "testing_text_labels = IO.load_csv_col('datasets/random_sample.csv', 'label')\n",
    "testing_text_labels = list(map(int, testing_text_labels[100:200]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification\n",
    "classifier_N_2_seed_set_LR = classify(model_N_2, LogisticRegression(), seed_set, Y)\n",
    "classifier_N_3_seed_set_LR = classify(model_N_3, LogisticRegression(), seed_set, Y)\n",
    "classifier_N_2_expanded_set_LR = classify(model_N_2, LogisticRegression(), seed_set_expanded_N_2, Y_N_2)\n",
    "classifier_N_3_expanded_set_LR = classify(model_N_3,LogisticRegression(),seed_set_expanded_N_3, Y_N_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_rate(X, Y):\n",
    "    count = 0\n",
    "    for i in range(len(X)):\n",
    "        if(X[i] == Y[i]):\n",
    "            count = count + 1\n",
    "    return (count/len(X))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted\n",
      "[0 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 0 0 0 1 0 0 0 1 0 0 1 1 1 0\n",
      " 1 0 0 0 0 1 0 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 1 1 1 0 0\n",
      " 0 0 1 1 1 1 0 0 1 1 1 0 0 1 0 0 1 0 0 0 1 1 0 1 1 0]\n",
      "Original\n",
      "[1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0]\n",
      "60.0\n"
     ]
    }
   ],
   "source": [
    "seed_set_N_2_result = classifier_N_2_seed_set_LR.predict(testing_text)\n",
    "seed_set_N_2_accuracy = accuracy_rate(testing_text_labels,seed_set_N_2_result)\n",
    "print('Predicted')\n",
    "print(seed_set_N_2_result)\n",
    "print('Original')\n",
    "print(testing_text_labels)\n",
    "print(seed_set_N_2_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61.0\n"
     ]
    }
   ],
   "source": [
    "seed_set_N_3_result = classifier_N_3_seed_set_LR.predict(testing_text)\n",
    "seed_set_N_3_accuracy = accuracy_rate(testing_text_labels,seed_set_N_3_result)\n",
    "print(seed_set_N_3_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67.0\n"
     ]
    }
   ],
   "source": [
    "classifier_N_2_expanded_set_result = classifier_N_2_expanded_set_LR.predict(\n",
    "    testing_text)\n",
    "classifier_N_2_expanded_set_accuracy = accuracy_rate(testing_text_labels,classifier_N_2_expanded_set_result)\n",
    "print(classifier_N_2_expanded_set_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67.0\n"
     ]
    }
   ],
   "source": [
    "classifier_N_3_expanded_set_result = classifier_N_3_expanded_set_LR.predict(testing_text)\n",
    "classifier_N_3_expanded_set_accuracy = accuracy_rate(testing_text_labels,classifier_N_3_expanded_set_result)\n",
    "print(classifier_N_3_expanded_set_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67.0\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "classifier_N_3_expanded_set_SVM = classify(model_N_3,svm.SVC(),seed_set_expanded_N_3, Y_N_3)\n",
    "classifier_N_3_expanded_set_result_SVM = classifier_N_3_expanded_set_SVM.predict(\n",
    "    testing_text)\n",
    "classifier_N_3_expanded_set_accuracy_SVM = accuracy_rate(testing_text_labels, classifier_N_3_expanded_set_result_SVM)\n",
    "print(classifier_N_3_expanded_set_accuracy_SVM)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ee5cc6fef2d70a7e71ee3826687cbd150f18158e0b1eef11d4f4f92bb920e304"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
