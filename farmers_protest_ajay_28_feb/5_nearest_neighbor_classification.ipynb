{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import fasttext\n",
    "import pandas as pd\n",
    "from scipy import spatial\n",
    "from scipy.spatial import distance\n",
    "from resources.basicIO import InputOutput as IO\n",
    "from resources.tokTT import CommentTokenizer\n",
    "from sklearn import svm\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FastTextTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\" Convert texts into their mean fastText vectors \"\"\"\n",
    "\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.stack([\n",
    "            np.mean([self.model[w] for w in text.split()], 0)\n",
    "            for text in X\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(small_model,predictor,lines,Y):\n",
    "    classifier = make_pipeline(\n",
    "        FastTextTransformer(model=small_model),\n",
    "        predictor\n",
    "    ).fit(\n",
    "        lines,\n",
    "        Y\n",
    "    )\n",
    "    return classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "# load models\n",
    "model_N_2 = fasttext.load_model('models/ft_unsupervised_N_2.bin')\n",
    "model_N_3 = fasttext.load_model('models/ft_unsupervised_N_3.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load seed set and tokenize\n",
    "seed_set = CommentTokenizer.cleaned(\"datasets/seed_set.txt\")\n",
    "# Load seed Labels\n",
    "Y = IO.load_nums(\"datasets/seed_set_labels.txt\")\n",
    "\n",
    "# Load expanded seed set\n",
    "seed_set_expanded_N_2 = CommentTokenizer.cleaned(\"datasets_post/seed_set_expanded_N_2.txt\")\n",
    "Y_N_2 = IO.load_nums(\"datasets_post/seed_set_expanded_labels_N_2.txt\")\n",
    "\n",
    "seed_set_expanded_N_3 = CommentTokenizer.cleaned(\"datasets_post/seed_set_expanded_N_3.txt\")\n",
    "Y_N_3 = IO.load_nums(\"datasets_post/seed_set_expanded_labels_N_3.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load testing set\n",
    "testing_text = IO.load_csv_col('datasets/random_sample.csv', 'comment')\n",
    "testing_text = testing_text[500:1000]\n",
    "testing_text_labels = IO.load_csv_col('datasets/random_sample.csv', 'label')\n",
    "testing_text_labels = list(map(int, testing_text_labels[500:1000]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification\n",
    "LR_ss_N_2 = classify(model_N_2, LogisticRegression(), seed_set, Y)\n",
    "LR_ss_N_3 = classify(model_N_3, LogisticRegression(), seed_set, Y)\n",
    "LR_es_N_2 = classify(model_N_2, LogisticRegression(),seed_set_expanded_N_2, Y_N_2)\n",
    "LR_es_N_3 = classify(model_N_3,LogisticRegression(),seed_set_expanded_N_3, Y_N_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_ss_N_2 = classify(model_N_2, svm.SVC(), seed_set, Y)\n",
    "SVM_ss_N_3 = classify(model_N_3, svm.SVC(), seed_set, Y)\n",
    "SVM_es_N_2 = classify(model_N_2, svm.SVC(), seed_set_expanded_N_2, Y_N_2)\n",
    "SVM_es_N_3 = classify(model_N_3, svm.SVC(), seed_set_expanded_N_3, Y_N_3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(('LR Seed Set N=2', LR_ss_N_2))\n",
    "models.append(('LR Seed Set N=3', LR_ss_N_3))\n",
    "models.append(('LR Expanded Set N=2', LR_es_N_2))\n",
    "models.append(('LR Expanded Set N=3', LR_es_N_3))\n",
    "models.append(('SVM Seed Set N=2', SVM_ss_N_2))\n",
    "models.append(('SVM Seed Set N=3', SVM_ss_N_3))\n",
    "models.append(('SVM Expanded Set N=2', SVM_es_N_2))\n",
    "models.append(('SVM Expanded Set N=3', SVM_es_N_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print output to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = open(\"results/output.txt\", \"a\")\n",
    "for i, v in models:\n",
    "    accuracy = metrics.accuracy_score(testing_text_labels, v.predict(testing_text))\n",
    "    confusion_matrix = metrics.confusion_matrix(testing_text_labels, v.predict(testing_text))\n",
    "    print('========= {} Model Test Results ==========='.format(i), file=outfile) \n",
    "    print(' ',file=outfile)\n",
    "    print(\"Model Accuracy:\" \"\\n\", accuracy, file=outfile)\n",
    "    print(' ', file=outfile)\n",
    "    print(\"Confusion matrix:\" \"\\n\", confusion_matrix, file=outfile)\n",
    "    print(' ', file=outfile)\n",
    "outfile.close()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ee5cc6fef2d70a7e71ee3826687cbd150f18158e0b1eef11d4f4f92bb920e304"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
