{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\AJAY\n",
      "[nltk_data]     BISWAS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\AJAY\n",
      "[nltk_data]     BISWAS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import os\n",
    "import nltk.corpus\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import bigrams, trigrams, ngrams\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Username</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Video ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pardeep Sandhu</td>\n",
       "      <td>Mam actually ek kisan ki death ho gyi hai usko...</td>\n",
       "      <td>0</td>\n",
       "      <td>0lrE3zoaCqI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sahab Singh</td>\n",
       "      <td>Ko bi</td>\n",
       "      <td>0</td>\n",
       "      <td>0lrE3zoaCqI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gurlal singh</td>\n",
       "      <td>Very bad BJP cm jjp</td>\n",
       "      <td>0</td>\n",
       "      <td>0lrE3zoaCqI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pc bansal</td>\n",
       "      <td>Kisan kalank  Tikait ko bhejo jail.</td>\n",
       "      <td>0</td>\n",
       "      <td>0lrE3zoaCqI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>harman bajwa</td>\n",
       "      <td>Kisan zindabad</td>\n",
       "      <td>0</td>\n",
       "      <td>0lrE3zoaCqI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40785</th>\n",
       "      <td>Rahul Kushwaha</td>\n",
       "      <td>Ese dekh MEWAR ki yaad aa rhi</td>\n",
       "      <td>0</td>\n",
       "      <td>jTrlAzXZJ5M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40786</th>\n",
       "      <td>Shreya Raj</td>\n",
       "      <td>May the moral of Panjshir warriors stay high ....</td>\n",
       "      <td>3</td>\n",
       "      <td>jTrlAzXZJ5M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40787</th>\n",
       "      <td>Monindra Mahato</td>\n",
       "      <td>INDIA ko vi Saran nahi dena hay</td>\n",
       "      <td>0</td>\n",
       "      <td>jTrlAzXZJ5M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40788</th>\n",
       "      <td>Akash Isadkar</td>\n",
       "      <td>Ha aur taliban ke 300 ladko Maar dala ye bhi b...</td>\n",
       "      <td>0</td>\n",
       "      <td>jTrlAzXZJ5M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40789</th>\n",
       "      <td>Lakhan Kushwaha</td>\n",
       "      <td>Maro ya maaro,ye Afghanistan kisi ke baap ka t...</td>\n",
       "      <td>0</td>\n",
       "      <td>jTrlAzXZJ5M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40790 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Username                                            Comment  \\\n",
       "0       Pardeep Sandhu  Mam actually ek kisan ki death ho gyi hai usko...   \n",
       "1          Sahab Singh                                              Ko bi   \n",
       "2         Gurlal singh                                Very bad BJP cm jjp   \n",
       "3            pc bansal                Kisan kalank  Tikait ko bhejo jail.   \n",
       "4         harman bajwa                                     Kisan zindabad   \n",
       "...                ...                                                ...   \n",
       "40785   Rahul Kushwaha                      Ese dekh MEWAR ki yaad aa rhi   \n",
       "40786       Shreya Raj  May the moral of Panjshir warriors stay high ....   \n",
       "40787  Monindra Mahato                    INDIA ko vi Saran nahi dena hay   \n",
       "40788    Akash Isadkar  Ha aur taliban ke 300 ladko Maar dala ye bhi b...   \n",
       "40789  Lakhan Kushwaha  Maro ya maaro,ye Afghanistan kisi ke baap ka t...   \n",
       "\n",
       "       Likes     Video ID  \n",
       "0          0  0lrE3zoaCqI  \n",
       "1          0  0lrE3zoaCqI  \n",
       "2          0  0lrE3zoaCqI  \n",
       "3          0  0lrE3zoaCqI  \n",
       "4          0  0lrE3zoaCqI  \n",
       "...      ...          ...  \n",
       "40785      0  jTrlAzXZJ5M  \n",
       "40786      3  jTrlAzXZJ5M  \n",
       "40787      0  jTrlAzXZJ5M  \n",
       "40788      0  jTrlAzXZJ5M  \n",
       "40789      0  jTrlAzXZJ5M  \n",
       "\n",
       "[40790 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../englishComments.csv\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text filtration\n",
    "def filteredTokens(line):\n",
    "\n",
    "    # remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(line)\n",
    "    filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
    "\n",
    "    punctuations = re.compile(r'[-,*%#&\"\\'`:+.?!;()|0-9]')    # remove punctuations\n",
    "    post_punctuations = []\n",
    "    for words in filtered_sentence:\n",
    "        word = punctuations.sub(\"\",words)\n",
    "        if len(word)>0:\n",
    "            post_punctuations.append(word)\n",
    "    \n",
    "    return post_punctuations\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python program for KMP Algorithm (works for both string and list) gfg\n",
    "def KMPSearch(pat, txt):\n",
    "\tM = len(pat)\n",
    "\tN = len(txt)\n",
    "\toutput = []\n",
    "\n",
    "\t# create lps[] that will hold the longest prefix suffix\n",
    "\t# values for pattern\n",
    "\tlps = [0]*M\n",
    "\tj = 0 # index for pat[]\n",
    "\n",
    "\t# Preprocess the pattern (calculate lps[] array)\n",
    "\tcomputeLPSArray(pat, M, lps)\n",
    "\n",
    "\ti = 0 # index for txt[]\n",
    "\twhile i < N:\n",
    "\t\tif pat[j] == txt[i]:\n",
    "\t\t\ti += 1\n",
    "\t\t\tj += 1\n",
    "\n",
    "\t\tif j == M:\n",
    "\t\t\toutput.append(i-j)\n",
    "\t\t\tj = lps[j-1]\n",
    "\n",
    "\t\t# mismatch after j matches\n",
    "\t\telif i < N and pat[j] != txt[i]:\n",
    "\t\t\t# Do not match lps[0..lps[j-1]] characters,\n",
    "\t\t\t# they will match anyway\n",
    "\t\t\tif j != 0:\n",
    "\t\t\t\tj = lps[j-1]\n",
    "\t\t\telse:\n",
    "\t\t\t\ti += 1\n",
    "\t\n",
    "\treturn output\n",
    "\n",
    "def computeLPSArray(pat, M, lps):\n",
    "\tlen = 0 # length of the previous longest prefix suffix\n",
    "\n",
    "\tlps[0] # lps[0] is always 0\n",
    "\ti = 1\n",
    "\n",
    "\t# the loop calculates lps[i] for i = 1 to M-1\n",
    "\twhile i < M:\n",
    "\t\tif pat[i] == pat[len]:\n",
    "\t\t\tlen += 1\n",
    "\t\t\tlps[i] = len\n",
    "\t\t\ti += 1\n",
    "\t\telse:\n",
    "\t\t\t# This is tricky. Consider the example.\n",
    "\t\t\t# AAACAAAA and i = 7. The idea is similar\n",
    "\t\t\t# to search step.\n",
    "\t\t\tif len != 0:\n",
    "\t\t\t\tlen = lps[len-1]\n",
    "\n",
    "\t\t\t\t# Also, note that we do not increment i here\n",
    "\t\t\telse:\n",
    "\t\t\t\tlps[i] = 0\n",
    "\t\t\t\ti += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finds all occurances of next word after target (string) in source (list)\n",
    "def nextWordOfPhrase(target, source):\n",
    "    \n",
    "    target = word_tokenize(target)\n",
    "    m = len(target)\n",
    "    n = len(source)\n",
    "\n",
    "    lst = KMPSearch(target,source)      # search all occurances of target\n",
    " \n",
    "    nextWords = []\n",
    "    # all next words\n",
    "    for val in lst:\n",
    "        if(m+val) < n:\n",
    "            nextWords.append(source[m+val])\n",
    "    \n",
    "    return nextWords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Farmers are and Farmers are not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud1 = []\n",
    "cloud2 = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    line = df.Comment[i]\n",
    "    line = str(line)\n",
    "    tokens = filteredTokens(line.lower())       # remove unnecessary words & punc.\n",
    "    p1 = nextWordOfPhrase('kisan',tokens)\n",
    "    p2 = nextWordOfPhrase('kisan nahi',tokens)\n",
    "    cloud1.extend(p1)\n",
    "    cloud2.extend(p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save in csv\n",
    "set1, count1 = np.unique(cloud1, return_counts=True)\n",
    "set2, count2 = np.unique(cloud2, return_counts=True)\n",
    "\n",
    "pd.DataFrame({'set1': set1, 'frequency': count1}).to_csv('perception_set1.csv', index=False)\n",
    "pd.DataFrame({'set2': set2, 'frequency': count2}).to_csv('perception_set2.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
