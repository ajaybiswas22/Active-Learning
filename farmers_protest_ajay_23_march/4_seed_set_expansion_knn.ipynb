{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from scipy import spatial\n",
    "from scipy.spatial import distance\n",
    "from resources.basicIO import InputOutput as IO\n",
    "from resources.filterLang import FilterLanguage as FL\n",
    "from resources.tokTT import CommentTokenizer as CT\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN(model, line, K):\n",
    "    return model.get_nearest_neighbors(line, k=K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes 2 vectors a, b and returns the cosine similarity according \n",
    "# to the definition of the dot product\n",
    "def cos_sim(a, b):\n",
    "\tdot_product = np.dot(a, b)\n",
    "\tnorm_a = np.linalg.norm(a)\n",
    "\tnorm_b = np.linalg.norm(b)\n",
    "\treturn dot_product / (norm_a * norm_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finds similarity score between two lists\n",
    "def intersection_score(words, lst1, lst2, score_type):\n",
    "    # words contains all the words in the corpus\n",
    "    v1 = []\n",
    "    v2 = []\n",
    "\n",
    "    l1 = [x[1] for x in lst1]\n",
    "    l2 = [x[1] for x in lst2]\n",
    "\n",
    "    l10 = [x[0] for x in lst1]\n",
    "    l20 = [x[0] for x in lst2]\n",
    "\n",
    "    for i in range(len(words)):\n",
    "        try:\n",
    "            v1.append(l10[l1.index(words[i])])\n",
    "        except:\n",
    "            v1.append(0)\n",
    "\n",
    "    for i in range(len(words)):\n",
    "        try:\n",
    "            v2.append(l20[l2.index(words[i])])\n",
    "        except:\n",
    "            v2.append(0)\n",
    "\n",
    "    if(score_type == 'cosine_sim'):\n",
    "        return cos_sim(np.array(v1), np.array(v2))\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "# load models\n",
    "model_N_2 = fasttext.load_model('models/ft_unsupervised_N_2.bin')\n",
    "model_N_3 = fasttext.load_model('models/ft_unsupervised_N_3.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Expansion Text and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading from 200th comments\n",
    "expansion_text = IO.load_csv_col('datasets/random_sample.csv','comment')\n",
    "expansion_text = expansion_text[0:500]\n",
    "expansion_text_labels = IO.load_csv_col('datasets/random_sample.csv','label')\n",
    "expansion_text_labels = list(map(str,map(int,expansion_text_labels[0:500])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize Expansion text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "expansion_TK = [CT.tokenize(x) for x in expansion_text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Seed Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_set_text = IO.load_text('datasets/seed_set.txt')\n",
    "seed_set_labels = IO.load_text('datasets/seed_set_labels.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize Seed Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_set_TK = CT.cleaned('datasets/seed_set.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### oracle interference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oracleHelp(classdata):\n",
    "    count = sum(classdata)\n",
    "    res = any((((ele/count) >= 0.40 and (ele/count) <= 0.60)\n",
    "              or ((ele/count) >= 0.90 and (ele/count) <= 1)) for ele in classdata)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expand Seed Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expands seed set, seed set labels and NN_seed_set based on scores and also verifies with user labels\n",
    "# words: model.words, d1: NN_seed_set, l2: NN_exp_corpus_line, seed_set: seed_set, corpus_comment: exp_line, Y: labels\n",
    "def expand(words, d1, l2, g_seed_set, g_corpus_comment, g_corpus_comment_label, Y, score_type, to_check='F',k=11):\n",
    "\n",
    "    scores = [intersection_score(words, i, l2, score_type) for i in d1]\n",
    "    maxpos = scores.index(max(scores))\n",
    "\n",
    "    scores_array = np.array(scores)\n",
    "\n",
    "    idx0 = 0\n",
    "    idx1 = 0\n",
    "    idx2 = 0\n",
    "    for i in range(len(scores)):\n",
    "        if(Y[i] == '0'):\n",
    "            idx0 += 1\n",
    "        elif(Y[i] == '1'):\n",
    "            idx1 += 1\n",
    "        elif(Y[i] == '2'):\n",
    "            idx2 += 1\n",
    "\n",
    "    # knn\n",
    "    idx = scores_array.argsort()[::-1][:k]\n",
    "\n",
    "    class_count = [0,0,0]\n",
    "\n",
    "    for i in range(len(idx)):\n",
    "        if(Y[idx[i]] == '0'):\n",
    "            class_count[0] += 1\n",
    "        elif(Y[idx[i]] == '1'):\n",
    "            class_count[1] += 1\n",
    "        elif(Y[idx[i]] == '2'):\n",
    "            class_count[2] += 1\n",
    "\n",
    "    max_class = class_count.index(max(class_count))\n",
    "    if(max_class == 0):\n",
    "        maxpos = idx0\n",
    "    elif(max_class == 1):\n",
    "        maxpos = idx1\n",
    "    elif(max_class == 2):\n",
    "        maxpos = idx2\n",
    "\n",
    "    try:\n",
    "        if(to_check == 'F'):\n",
    "            d1.insert(Y.index(Y[maxpos]), l2)\n",
    "            g_seed_set.insert(Y.index(Y[maxpos]), g_corpus_comment)\n",
    "            Y.insert(Y.index(Y[maxpos]), Y[maxpos])\n",
    "        elif(to_check == 'T' and oracleHelp(class_count) == False):\n",
    "            d1.insert(Y.index(Y[maxpos]), l2)\n",
    "            g_seed_set.insert(Y.index(Y[maxpos]), g_corpus_comment)\n",
    "            Y.insert(Y.index(Y[maxpos]), Y[maxpos])\n",
    "        elif(to_check == 'T' and oracleHelp(class_count) == True):\n",
    "            \n",
    "            if(Y[maxpos] != g_corpus_comment_label):\n",
    "                d1.insert(Y.index(g_corpus_comment_label), l2)\n",
    "                g_seed_set.insert(\n",
    "                    Y.index(g_corpus_comment_label), g_corpus_comment)\n",
    "                Y.insert(Y.index(g_corpus_comment_label),\n",
    "                         g_corpus_comment_label)\n",
    "            else:\n",
    "                d1.insert(Y.index(Y[maxpos]), l2)\n",
    "                g_seed_set.insert(Y.index(Y[maxpos]), g_corpus_comment)\n",
    "                Y.insert(Y.index(Y[maxpos]), Y[maxpos])\n",
    "\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_seed_set(model,\n",
    "                    seed_set_text,\n",
    "                    seed_set_labels,\n",
    "                    seed_set_TK,\n",
    "                    expansion_text,\n",
    "                    expansion_TK, \n",
    "                    neighbors=10,\n",
    "                    expand_limit=500,\n",
    "                    score_type='cosine_sim'):\n",
    "    \n",
    "    # nearest neighbors of seed set\n",
    "    NN_seed_set = []\n",
    "    for comment in seed_set_TK:\n",
    "        NN_seed_set.append(NN(model,comment,neighbors))\n",
    "\n",
    "    # nearest neigbors for unlabeled corpus from random sample\n",
    "    NN_exp_corpus = []\n",
    "    for comment in expansion_TK:\n",
    "        NN_exp_corpus.append(NN(model,comment,neighbors))\n",
    "\n",
    "    # seed set to be expanded\n",
    "    seed_text_expanded = copy.deepcopy(seed_set_text)\n",
    "    Y_expanded = copy.deepcopy(seed_set_labels)\n",
    "    NN_seed_set_expanded = copy.deepcopy(NN_seed_set)\n",
    "\n",
    "    # expand by expand_limit\n",
    "    for i in range(expand_limit):\n",
    "        \n",
    "        to_check = 'T'\n",
    "        expand(model.words,\n",
    "               NN_seed_set_expanded,\n",
    "               NN_exp_corpus[i],\n",
    "               seed_text_expanded,\n",
    "               expansion_text[i],\n",
    "               expansion_text_labels[i],\n",
    "               Y_expanded,\n",
    "               score_type,\n",
    "               to_check)\n",
    "\n",
    "    return seed_text_expanded, Y_expanded     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0000000000000002, 0.18551344512687232, 0.10452660622148399, 0.19489851037168862, 0.31850144708599953]\n",
      "[0.18551344512687232, 0.9999999999999999, 0.094285120003458, 0.09826398276262557, 0.28413964886302123, 0.18551344512687232]\n",
      "[0.10452660622148399, 0.094285120003458, 1.0, 0.31710288074868553, 0.3055033118033098, 0.10452660622148399, 0.094285120003458]\n",
      "[0.19489851037168862, 0.09826398276262557, 0.31710288074868553, 1.0, 0.6066372569044701, 0.19489851037168862, 0.09826398276262557, 0.31710288074868553]\n",
      "[0.31850144708599953, 0.28413964886302123, 0.3055033118033098, 0.6066372569044701, 1.0, 0.31850144708599953, 0.28413964886302123, 0.3055033118033098, 0.6066372569044701]\n"
     ]
    }
   ],
   "source": [
    "seed_text_expanded_N_2,Y_expanded_N_2 = expand_seed_set(model_N_2,\n",
    "                                         seed_set_text,\n",
    "                                         seed_set_labels,\n",
    "                                         seed_set_TK,\n",
    "                                         expansion_text,\n",
    "                                         expansion_TK)\n",
    "\n",
    "IO.save_text('datasets_post/seed_set_expanded_N_2.txt', seed_text_expanded_N_2)\n",
    "IO.save_text('datasets_post/seed_set_expanded_labels_N_2.txt',\n",
    "             map(str, Y_expanded_N_2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 0.1862732894317705, 0.10651768110304326, 0.29664320041596426, 0.3172345372749772]\n",
      "[0.1862732894317705, 1.0, 0.0, 0.08514786599917908, 0.1934958547410296, 0.1862732894317705]\n",
      "[0.10651768110304326, 0.0, 1.0000000000000002, 0.3110488452574277, 0.19762872409985488, 0.10651768110304326, 0.0]\n",
      "[0.29664320041596426, 0.08514786599917908, 0.3110488452574277, 1.0, 0.5090530468975454, 0.29664320041596426, 0.08514786599917908, 0.3110488452574277]\n",
      "[0.3172345372749772, 0.1934958547410296, 0.19762872409985488, 0.5090530468975454, 1.0, 0.3172345372749772, 0.1934958547410296, 0.19762872409985488, 0.5090530468975454]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "seed_text_expanded_N_3,Y_expanded_N_3 = expand_seed_set(model_N_3,\n",
    "                                         seed_set_text,\n",
    "                                         seed_set_labels,\n",
    "                                         seed_set_TK,\n",
    "                                         expansion_text,\n",
    "                                         expansion_TK)\n",
    "\n",
    "IO.save_text('datasets_post/seed_set_expanded_N_3.txt', seed_text_expanded_N_3)\n",
    "IO.save_text('datasets_post/seed_set_expanded_labels_N_3.txt',\n",
    "             map(str, Y_expanded_N_3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.7980720400810242, 'farmersprotest'), (0.7745435237884521, 'isupportfarmers'), (0.7717570066452026, 'farmerprotest'), (0.7532146573066711, 'nofarmernofood'), (0.7147347331047058, 'wesupportfarmers'), (0.7041870355606079, 'supportfarmers'), (0.6495168209075928, 'nofarmersnofood'), (0.6266491413116455, 'standwithfarmers'), (0.5907376408576965, 'thank'), (0.5797268748283386, '</s>'), (0.5791415572166443, 'joy'), (0.5759825706481934, 'istandwithfarmers'), (0.5726712942123413, 'support'), (0.5669645667076111, 'protest'), (0.5421419143676758, 'thanks'), (0.5400951504707336, 'love'), (0.5380334854125977, 'shoulder'), (0.5269688963890076, 'stand'), (0.5235479474067688, 'majdoor'), (0.5181511044502258, 'salute')]\n",
      "\n",
      "[(0.7923978567123413, 'farmersprotest'), (0.6964684128761292, 'farmerprotest'), (0.6697428226470947, 'isupportfarmers'), (0.6593414545059204, 'nofarmernofood'), (0.6586105823516846, 'supportfarmers'), (0.6492010951042175, 'wesupportfarmers'), (0.5962943434715271, '</s>'), (0.593979001045227, 'nofarmersnofood'), (0.5750954747200012, 'standwithfarmers'), (0.5610840916633606, 'shoulder'), (0.5467197895050049, 'protest'), (0.5405521392822266, 'papa'), (0.5349021553993225, 'aj'), (0.5235241055488586, 'thank'), (0.518370509147644, 'istandwithfarmers'), (0.5111730098724365, 'joy'), (0.5003200769424438, 'dc'), (0.4977627098560333, 'sandeep'), (0.4966147840023041, 'resolution'), (0.4934174120426178, 'hat')]\n",
      "\n",
      "[(0.654762864112854, 'good'), (0.5946751832962036, 'actually'), (0.5681045651435852, 'understand'), (0.5670098066329956, 'contractual'), (0.5470722913742065, 'laws'), (0.5459299087524414, 'better'), (0.5413401126861572, 'would'), (0.5405133962631226, 'bills'), (0.5383009910583496, 'new'), (0.533521294593811, 'not'), (0.5278599262237549, 'farm'), (0.5236343145370483, 'wether'), (0.522127628326416, 'need'), (0.520900547504425, 'sounds'), (0.5200082659721375, 'think'), (0.5191491842269897, 'market'), (0.519136905670166, 'theoretically'), (0.5182822346687317, 'benefit'), (0.5170084238052368, 'oversight'), (0.5137137770652771, 'bill')]\n"
     ]
    }
   ],
   "source": [
    "# Nearest Neighbors\n",
    "c1 = NN(model_N_2,'I support the farmers protest',20)\n",
    "c2 = NN(model_N_2,'I am against the farmers protest',20)\n",
    "c3 = NN(model_N_2, 'the farm bills are actually good the govt is doing right', 20)\n",
    "print(c1)\n",
    "print()\n",
    "print(c2)\n",
    "print()\n",
    "print(c3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7753610454922774"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cosine similarity\n",
    "intersection_score(model_N_2.words,c1,c2,'cosine_sim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intersection_score(model_N_2.words,c2,c3,'cosine_sim')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ee5cc6fef2d70a7e71ee3826687cbd150f18158e0b1eef11d4f4f92bb920e304"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
