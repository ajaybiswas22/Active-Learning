{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resources.filterLang import FilterLanguage as FL\n",
    "from resources.tokTT import CommentTokenizer as CT\n",
    "import fasttext\n",
    "import numpy as np\n",
    "from resources.basicIO import InputOutput as IO\n",
    "import copy\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import common_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = sorted(set(open('datasets/tokenized_corpus.txt').read().split()))\n",
    "#res = dict.fromkeys(words, []) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN(model, line, K):\n",
    "\n",
    "    res = {}\n",
    "    for word in words:\n",
    "        res[word] = []\n",
    "\n",
    "    res2 = {}\n",
    "    for word in words:\n",
    "        res2[word] = 0\n",
    "\n",
    "    for wrd in line:\n",
    "        try:\n",
    "            x = model.wv.most_similar(wrd, topn=K)\n",
    "            for a, b in x:\n",
    "                res[a] = res[a] + [b]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    for i in res:\n",
    "        if(len(res[i]) == 0):\n",
    "            res2[i] = 0 \n",
    "        else:\n",
    "            res2[i] = np.mean(res[i])\n",
    "\n",
    "    lst = [(k, v) for v, k in res2.items()]\n",
    "    lst = sorted(lst, key=lambda x:x[0], reverse=True)\n",
    "\n",
    "    return lst[0:K]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oracleHelp(classdata):\n",
    "\n",
    "    sums = sum(classdata)\n",
    "    res = any(((ele/sums) >= 0.48 and (ele/sums) <= 0.52) for ele in classdata)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(a, b):\n",
    "\tdot_product = np.dot(a, b)\n",
    "\tnorm_a = np.linalg.norm(a)\n",
    "\tnorm_b = np.linalg.norm(b)\n",
    "\treturn dot_product / (norm_a * norm_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim(x,y,sim_type='cosine_sim'):\n",
    "\n",
    "    if(sim_type == 'cosine_sim'):\n",
    "        return cos_sim(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find similarity score matrix between A and B\n",
    "# pass transpose of B\n",
    "def sim_matrix(A, B, sim_type):\n",
    "    m, p = A.shape\n",
    "    p, n = B.shape\n",
    "    C = np.zeros((m, n))\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            C[i][j] = sim(A[i, :], B[:, j], sim_type)\n",
    "    return C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finds similarity score\n",
    "def score(model, line, k=10):\n",
    "    # words contains all the words in the corpus\n",
    "    lst1 = NN(model, line, k)\n",
    "    v1 = []\n",
    "    l1 = [x[1] for x in lst1]\n",
    "    l10 = [x[0] for x in lst1]\n",
    "    for i in range(len(words)):\n",
    "        try:\n",
    "            v1.append(l10[l1.index(words[i])])\n",
    "        except:\n",
    "            v1.append(0)\n",
    "    return v1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finds classwise average and returns an array of predicted\n",
    "# class labels. labels are classwise labels in ascending order\n",
    "def label_avg(X, labels,count,exp_labels=None):\n",
    "\n",
    "    m, n = X.shape\n",
    "    if(m != len(labels)):\n",
    "        return None\n",
    "\n",
    "    avg_sums = []\n",
    "    no_labels = len(list(set(labels)))\n",
    "\n",
    "    for p in range(n):\n",
    "\n",
    "        column = X[:, p]\n",
    "\n",
    "        avgs = np.zeros(no_labels)\n",
    "\n",
    "        for lbl in range(no_labels):\n",
    "            indices = [ix for ix, label in enumerate(labels) if label == lbl]\n",
    "            avgs[lbl] = np.mean([column[x] for x in indices])\n",
    "\n",
    "        if(exp_labels != None and oracleHelp(avgs)):\n",
    "            avg_sums.append(exp_labels[p])\n",
    "            count[0]+=1\n",
    "        else:\n",
    "            max_avg_pos = avgs.argmax()\n",
    "            avg_sums.append(max_avg_pos)\n",
    "\n",
    "    return avg_sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_NN(model,lines_TK,k):\n",
    "    scores = []\n",
    "    for line in lines_TK:\n",
    "        scores.append(score(model, line, k))\n",
    "\n",
    "    return scores  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_N_2 = Word2Vec.load(\"models/word2vec.model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load comments, seedset, labels of both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading 60 comments\n",
    "expansion_text = IO.load_csv_col('datasets/random_sample.csv', 'comment')\n",
    "expansion_text = expansion_text[0:500]\n",
    "expansion_text_labels = IO.load_csv_col('datasets/random_sample.csv', 'label')\n",
    "expansion_text_labels = list(map(int, expansion_text_labels[0:500]))\n",
    "seed_set_text = IO.load_text('datasets/seed_set.txt')\n",
    "seed_set_labels = IO.load_text('datasets/seed_set_labels.txt')\n",
    "seed_set_labels = list(map(int, seed_set_labels))\n",
    "seed_set_TK = CT.cleaned('datasets/seed_set.txt')\n",
    "expansion_TK = [CT.tokenize(x) for x in expansion_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select comments from expansion_set in batches\n",
    "batch_size = 20\n",
    "k = 30\n",
    "\n",
    "M = np.arange(0,500,batch_size)\n",
    "\n",
    "seed_TK = copy.deepcopy(seed_set_TK)\n",
    "seed_labels = copy.deepcopy(seed_set_labels)\n",
    "seed_text = copy.deepcopy(seed_set_text)\n",
    "\n",
    "count2 = [0]\n",
    "for i in range(1, len(M)):\n",
    "    \n",
    "    exp_TK = expansion_TK[M[i-1]:M[i]]\n",
    "    exp_labels = expansion_text_labels[M[i-1]:M[i]]\n",
    "\n",
    "    # find NN\n",
    "    seed_NN = get_NN(model_N_2,seed_TK,k)\n",
    "    exp_NN = get_NN(model_N_2,exp_TK,k)\n",
    "\n",
    "    A = np.array(seed_NN)\n",
    "    B = np.array(exp_NN).T\n",
    "    C = sim_matrix(A,B,'cosine_sim')\n",
    "    #Y = label_avg(C, seed_labels, count2)\n",
    "    Y = label_avg(C, seed_labels, count2, exp_labels)\n",
    "    seed_labels += Y\n",
    "    seed_TK += exp_TK\n",
    "    seed_text += expansion_text[M[i-1]:M[i]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seeds = [x for _,x in sorted(zip(seed_labels,seed_text))]\n",
    "#Y = [y for y,_ in sorted(zip(seed_labels,seed_text))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "IO.save_text('datasets_post/batch_N_2.txt', seed_text)\n",
    "IO.save_text('datasets_post/batch_labels_N_2.txt',map(str, seed_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22]\n"
     ]
    }
   ],
   "source": [
    "print(count2)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ee5cc6fef2d70a7e71ee3826687cbd150f18158e0b1eef11d4f4f92bb920e304"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
